import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

class FourierProjection(nn.Module):
    """Fourier projection layer for time embeddings."""
    def __init__(self, embedding_size, factor=25.):
        super().__init__()
        self.projection_weights = nn.Parameter(torch.randn(embedding_size // 2) * factor, requires_grad=False)

    def forward(self, time_tensor):
        projection = time_tensor[:, None] * self.projection_weights[None, :] * 2 * np.pi
        return torch.cat([torch.sin(projection), torch.cos(projection)], dim=-1)

class LinearLayer(nn.Module):
    """Linear layer followed by reshaping."""
    def __init__(self, input_size, output_size):
        super().__init__()
        self.linear = nn.Linear(input_size, output_size)

    def forward(self, inputs):
        return self.linear(inputs)[..., None, None]

class SimpleUNet(nn.Module):
    """Simplified UNet-based score network for time-dependent denoising."""
    def __init__(self, noise_std_fn, feature_sizes=[32, 64, 128], time_embedding_size=256):
        super().__init__()
        # Time embedding with Fourier projections
        self.time_embed = nn.Sequential(
            FourierProjection(embedding_size=time_embedding_size),
            nn.Linear(time_embedding_size, time_embedding_size)
        )

        # Encoder layers
        self.encoder_conv1 = nn.Conv2d(1, feature_sizes[0], kernel_size=3, stride=1, bias=False)
        self.embed_layer1 = LinearLayer(time_embedding_size, feature_sizes[0])
        self.norm1 = nn.GroupNorm(4, feature_sizes[0])

        self.encoder_conv2 = nn.Conv2d(feature_sizes[0], feature_sizes[1], kernel_size=3, stride=2, bias=False)
        self.embed_layer2 = LinearLayer(time_embedding_size, feature_sizes[1])
        self.norm2 = nn.GroupNorm(32, feature_sizes[1])

        self.encoder_conv3 = nn.Conv2d(feature_sizes[1], feature_sizes[2], kernel_size=3, stride=2, bias=False)
        self.embed_layer3 = LinearLayer(time_embedding_size, feature_sizes[2])
        self.norm3 = nn.GroupNorm(32, feature_sizes[2])

        # Decoder layers
        self.decoder_conv3 = nn.ConvTranspose2d(feature_sizes[2], feature_sizes[1], kernel_size=3, stride=2, bias=False)
        self.embed_layer4 = LinearLayer(time_embedding_size, feature_sizes[1])
        self.norm4 = nn.GroupNorm(32, feature_sizes[1])

        self.decoder_conv2 = nn.ConvTranspose2d(feature_sizes[1] * 2, feature_sizes[0], kernel_size=3, stride=2, bias=False, output_padding=1)
        self.embed_layer5 = LinearLayer(time_embedding_size, feature_sizes[0])
        self.norm5 = nn.GroupNorm(32, feature_sizes[0])

        self.final_conv = nn.ConvTranspose2d(feature_sizes[0] * 2, 1, kernel_size=3, stride=1)

        self.noise_std_fn = noise_std_fn
        self.activate = lambda x: x * torch.sigmoid(x)

    def forward(self, input_image, time_tensor):
        # Time embedding
        time_embed = self.activate(self.time_embed(time_tensor))

        # Encoding path
        enc1 = self.encoder_conv1(input_image)
        enc1 += self.embed_layer1(time_embed)
        enc1 = self.norm1(enc1)
        enc1 = self.activate(enc1)

        enc2 = self.encoder_conv2(enc1)
        enc2 += self.embed_layer2(time_embed)
        enc2 = self.norm2(enc2)
        enc2 = self.activate(enc2)

        enc3 = self.encoder_conv3(enc2)
        enc3 += self.embed_layer3(time_embed)
        enc3 = self.norm3(enc3)
        enc3 = self.activate(enc3)

        # Decoding path
        dec3 = self.decoder_conv3(enc3)
        dec3 += self.embed_layer4(time_embed)
        dec3 = self.norm4(dec3)
        dec3 = self.activate(dec3)

        dec2 = self.decoder_conv2(torch.cat([dec3, enc2], dim=1))
        dec2 += self.embed_layer5(time_embed)
        dec2 = self.norm5(dec2)
        dec2 = self.activate(dec2)

        output = self.final_conv(torch.cat([dec2, enc1], dim=1))

        # Normalize output based on time
        output = output / self.noise_std_fn(time_tensor)[:, None, None, None]
        return output

import functools

# Set the device, either 'cuda' or 'cpu'
compute_device = 'cuda'  # Use 'cuda' for GPU, 'cpu' for CPU

def compute_std(t_steps, noise_sigma):
    """Compute the standard deviation for marginal probability.

    Args:
        t_steps: A tensor of time steps.
        noise_sigma: The noise scale parameter for the SDE.

    Returns:
        The computed standard deviation.
    """
    t_steps = torch.tensor(t_steps, device=compute_device)
    log_term = np.log(noise_sigma)
    return torch.sqrt((noise_sigma**(2 * t_steps) - 1.0) / (2 * log_term))

def compute_diff_coeff(t_steps, noise_sigma):
    """Compute the diffusion coefficient for the SDE.

    Args:
        t_steps: A tensor of time steps.
        noise_sigma: The noise scale parameter for the SDE.

    Returns:
        The diffusion coefficient vector.
    """
    return torch.tensor(noise_sigma**t_steps, device=compute_device)

# Set sigma value
sigma_value = 25.0

# Create functions for computing standard deviation and diffusion coefficient using sigma_value
std_fn = functools.partial(compute_std, noise_sigma=sigma_value)
diff_coeff_fn = functools.partial(compute_diff_coeff, noise_sigma=sigma_value)

def compute_loss(score_model, data_batch, compute_std_fn, tolerance=1e-5):
    """Loss function for training score-based models.

    Args:
        score_model: PyTorch model representing the time-dependent score network.
        data_batch: A mini-batch of input training data.
        compute_std_fn: Function to compute the standard deviation of the perturbation.
        tolerance: Small value to ensure numerical stability.
    """
    # Sample random times uniformly from the range (eps, 1)
    random_times = torch.rand(data_batch.shape[0], device=data_batch.device) * (1.0 - tolerance) + tolerance
    noise = torch.randn_like(data_batch)  # Generate Gaussian noise
    std_values = compute_std_fn(random_times)  # Compute the standard deviation using the marginal probability function
    perturbed_data = data_batch + noise * std_values[:, None, None, None]  # Add noise to the data
    model_output = score_model(perturbed_data, random_times)  # Get the model's output score
    
    # Calculate the loss
    loss_value = torch.mean(torch.sum((model_output * std_values[:, None, None, None] + noise) ** 2, dim=(1, 2, 3)))
    return loss_value

import torch
import torchmetrics
from torch.optim import Adam
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from torchvision.datasets import MNIST
import matplotlib.pyplot as plt
from tqdm.notebook import tqdm
from torchmetrics.image.fid import FrechetInceptionDistance

# Define your score-based model and loss function elsewhere in the code
model = torch.nn.DataParallel(ScoreNet(marginal_prob_std=marginal_prob_std_fn))
model = model.to(device)

# Hyperparameters
epochs = 100  # Number of epochs
batch_sz = 32  # Batch size
learning_rate = 1e-4  # Learning rate

# Load the MNIST dataset
mnist_data = MNIST('.', train=True, transform=transforms.ToTensor(), download=True)
train_loader = DataLoader(mnist_data, batch_size=batch_sz, shuffle=True, num_workers=4)

# Define optimizer
optim = Adam(model.parameters(), lr=learning_rate)

# List to store loss values
train_losses = []

# Main training loop
progress = tqdm(range(epochs))
for epoch in progress:
    epoch_loss = 0.
    total_samples = 0
    for batch_data, _ in train_loader:
        batch_data = batch_data.to(device)

        # Compute the loss using the model and loss function
        loss = compute_loss(model, batch_data, compute_std_fn)

        # Perform backpropagation and optimization
        optim.zero_grad()
        loss.backward()
        optim.step()

        epoch_loss += loss.item() * batch_data.shape[0]
        total_samples += batch_data.shape[0]

        # Assuming model can generate images for Inception Score calculation
        generated_imgs = model(batch_data)  
        inception_metric.update(generated_imgs)

    avg_epoch_loss = epoch_loss / total_samples
    train_losses.append(avg_epoch_loss)

    # Update progress bar with average loss
    progress.set_description(f'Epoch {epoch+1}, Avg Loss: {avg_epoch_loss:.5f}')

    # Save model checkpoint
    torch.save(model.state_dict(), 'model_checkpoint.pth')


# Plot training loss over epochs
plt.figure(figsize=(10, 6))
plt.plot(range(1, epochs+1), train_losses, label='Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.legend()
plt.show()
