import torch
import torch.nn as nn
import torchvision
import numpy as np
import matplotlib.pyplot as plt
from torchvision import transforms
from torch.optim import Adam
from torch.utils.data import DataLoader
from torchvision.datasets import MNIST
from tqdm import trange, tqdm
from torchvision.utils import make_grid
from einops import rearrange
import functools

# Load MNIST dataset
def load_data(batch_size):
    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])
    dataset = MNIST(root='./data', train=True, transform=transform, download=True)
    return DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Time Embedding
class TimeEmbed(nn.Module):
    def __init__(self, embed_dim, scale=30.0):
        super().__init__()
        self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)

    def forward(self, x):
        x_proj = x[:, None] * self.W[None, :] * 2 * np.pi
        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)

# Simple fully connected layer
class FCBlock(nn.Module):
    def __init__(self, input_dim, output_dim):
        super().__init__()
        self.fc = nn.Linear(input_dim, output_dim)

    def forward(self, x):
        return self.fc(x)[..., None, None]

# U-Net model
class SimpleUNet(nn.Module):
    def __init__(self, sigma_fn, channels=[32, 64, 128, 256], embed_dim=256):
        super().__init__()
        self.sigma_fn = sigma_fn
        self.time_embed = nn.Sequential(TimeEmbed(embed_dim), nn.Linear(embed_dim, embed_dim))

        # Encoding path
        self.enc1 = nn.Conv2d(1, channels[0], 3, padding=1, bias=False)
        self.enc2 = nn.Conv2d(channels[0], channels[1], 3, stride=2, padding=1, bias=False)
        self.enc3 = nn.Conv2d(channels[1], channels[2], 3, stride=2, padding=1, bias=False)
        self.enc4 = nn.Conv2d(channels[2], channels[3], 3, stride=2, padding=1, bias=False)

        # Decoding path
        self.dec4 = nn.ConvTranspose2d(channels[3], channels[2], 3, stride=2, output_padding=1, bias=False)
        self.dec3 = nn.ConvTranspose2d(channels[2], channels[1], 3, stride=2, output_padding=1, bias=False)
        self.dec2 = nn.ConvTranspose2d(channels[1], channels[0], 3, stride=2, output_padding=1, bias=False)
        self.dec1 = nn.ConvTranspose2d(channels[0], 1, 3, padding=1, bias=False)

        # Activation and normalization
        self.gn = nn.GroupNorm(4, num_channels=channels[0])
        self.act = lambda x: x * torch.sigmoid(x)

    def forward(self, x, t):
        t_emb = self.act(self.time_embed(t))

        # Encoding
        h1 = self.enc1(x)
        h2 = self.enc2(self.gn(h1 + t_emb))
        h3 = self.enc3(self.gn(h2 + t_emb))
        h4 = self.enc4(self.gn(h3 + t_emb))

        # Decoding
        d4 = self.dec4(h4)
        d3 = self.dec3(self.gn(d4 + h3 + t_emb))
        d2 = self.dec2(self.gn(d3 + h2 + t_emb))
        d1 = self.dec1(self.gn(d2 + h1 + t_emb))

        return d1 / self.sigma_fn(t)[:, None, None, None]

# Marginal standard deviation
def marginal_prob(t, sigma):
    return torch.sqrt((sigma**(2 * t) - 1) / (2 * np.log(sigma)))

# Diffusion coefficient
def diffusion_coeff(t, sigma):
    return torch.tensor(sigma**t, device=t.device)

# Loss function for score-based model
def score_loss(model, x, sigma_fn, eps=1e-5):
    random_t = torch.rand(x.shape[0], device=x.device) * (1 - 2 * eps) + eps
    noise = torch.randn_like(x)
    perturbed_x = x + noise * sigma_fn(random_t)[:, None, None, None]
    score = model(perturbed_x, random_t)
    return torch.mean(torch.sum((score * sigma_fn(random_t)[:, None, None, None] + noise)**2, dim=(1, 2, 3)))

# Euler-Maruyama sampler
def sample_em(model, sigma_fn, diff_coeff_fn, batch_size=64, img_shape=(1, 28, 28), steps=500, device='cuda'):
    t = torch.ones(batch_size, device=device)
    x = torch.randn(batch_size, *img_shape, device=device) * sigma_fn(t)[:, None, None, None]
    time_steps = torch.linspace(1., 1e-3, steps, device=device)
    step_size = time_steps[0] - time_steps[1]

    for step in tqdm(time_steps):
        batch_t = torch.ones(batch_size, device=device) * step
        g = diff_coeff_fn(batch_t)
        x = x + (g**2)[:, None, None, None] * model(x, batch_t) * step_size + g[:, None, None, None] * torch.randn_like(x)
    return x.clamp(0, 1)

# Training Loop
device = "cuda"
sigma_val = 25.0
sigma_fn = functools.partial(marginal_prob, sigma=sigma_val)
diff_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma_val)

# Initialize model and optimizer
unet_model = SimpleUNet(sigma_fn).to(device)
optimizer = Adam(unet_model.parameters(), lr=5e-4)

# Load MNIST data
train_loader = load_data(batch_size=2048)

# Train the model
for epoch in trange(50):
    avg_loss = 0
    num_items = 0
    for data, _ in tqdm(train_loader):
        data = data.to(device)
        loss = score_loss(unet_model, data, sigma_fn)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        avg_loss += loss.item() * data.size(0)
        num_items += data.size(0)
    print(f'Epoch {epoch+1}, Loss: {avg_loss / num_items}')

# Sampling
samples = sample_em(unet_model, sigma_fn, diff_coeff_fn, batch_size=64, steps=500, device=device)

# Plot generated samples
plt.figure(figsize=(6, 6))
plt.axis('off')
plt.imshow(make_grid(samples, nrow=8).permute(1, 2, 0).cpu())
plt.show()
